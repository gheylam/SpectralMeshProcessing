{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "43be756d",
   "metadata": {},
   "source": [
    "# SPoOkY Meshes ðŸ‘»"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "312567a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import base64\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import meshplot as mp\n",
    "\n",
    "import scipy.sparse\n",
    "import scipy.sparse.linalg\n",
    "import meshio\n",
    "import IPython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "56d025d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_mesh(filename):\n",
    "    m = meshio.read(filename)\n",
    "    v = m.points\n",
    "    f = m.cells[0].data\n",
    "    return v, f\n",
    "\n",
    "\n",
    "def save_mesh(filename, v, f):\n",
    "    m  = meshio.Mesh(v, f)\n",
    "    m.write(filename)\n",
    "\n",
    "\n",
    "# v1, f1 = load_mesh('cw2_meshes/curvatures/plane.obj')\n",
    "# v2, f2 = load_mesh('cw2_meshes/curvatures/lilium_s.obj')\n",
    "# v3, f3 = load_mesh('cw2_meshes/decompose/armadillo.obj')\n",
    "# v4, f4 = load_mesh('cw2_meshes/smoothing/fandisk_ns.obj')\n",
    "# v5, f5 = load_mesh('cw2_meshes/smoothing/plane_ns.obj')\n",
    "v7, f7 = load_mesh('sappho-hires.obj')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "id": "2946df0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def standardize(v):\n",
    "    \"\"\"\n",
    "    recenter points\n",
    "    \"\"\"\n",
    "    v = v - np.mean(v, axis=0)\n",
    "    v = v / np.std(v, axis=0).max()\n",
    "    return v\n",
    "\n",
    "\n",
    "def percentile_clip(h, n):\n",
    "    \"\"\"\n",
    "    reject outlier points\n",
    "    \"\"\"\n",
    "    return np.clip(h, np.percentile(h, n), np.percentile(h, 100 - n))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 640,
   "id": "ea7cb466",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unsexy test mesh for debugging\n",
    "v0 = np.array([\n",
    "    [ 0, 0, 0],\n",
    "    [-3, 4, 0],\n",
    "    [-6, 0, 0],\n",
    "    [-3,-4, 0],\n",
    "    [ 3,-4, 0],\n",
    "    [ 6, 0, 0],\n",
    "    [ 3, 4, 0],\n",
    "], dtype=np.float32)\n",
    "\n",
    "f0 = np.array([\n",
    "    [0, 1, 2],\n",
    "    [0, 2, 3],\n",
    "    [0, 3, 4],\n",
    "    [0, 4, 5],\n",
    "    [0, 5, 6],\n",
    "    [0, 1, 6],\n",
    "], dtype=np.int32)\n",
    "\n",
    "# perturbed vertex indices to throw off naive algorithms\n",
    "# f0 = np.array([\n",
    "#     [1, 0, 2],\n",
    "#     [2, 3, 0],\n",
    "#     [0, 3, 4],\n",
    "#     [4, 0, 5],\n",
    "#     [5, 6, 0],\n",
    "#     [6, 1, 0],\n",
    "# ], dtype=np.int32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1db97ec7",
   "metadata": {},
   "source": [
    "## Laplace-Beltrami and Friends"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88133b99",
   "metadata": {},
   "source": [
    "### Vertex Area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1832,
   "id": "60899957",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(v):\n",
    "    \"\"\"\n",
    "    normalize rows of vectors\n",
    "    \"\"\"\n",
    "    n = v.T / np.linalg.norm(v, axis=1)\n",
    "    return n.T\n",
    "\n",
    "\n",
    "def edges(f, n):\n",
    "    \"\"\"\n",
    "    build an adjacency matrix, return edges in only one direction (upper triangular)\n",
    "    \"\"\"\n",
    "    A = sp.sparse.triu(adjacency(f, len(v)))\n",
    "    ei, ej = A.nonzero()\n",
    "    ed = np.vstack([ei, ej]).T\n",
    "    #Â sort for consistency\n",
    "    return np.sort(ed, axis=0)\n",
    "\n",
    "\n",
    "def adjacency(f, n):\n",
    "    \"\"\"\n",
    "    build a sparse adjacency matrix from faces in coordinate format.\n",
    "    faces have some redundancy which we use a bitmask to filter.\n",
    "    \"\"\"\n",
    "    A = sp.sparse.dok_matrix((n, n), dtype=bool)\n",
    "    i, j, k = f.T\n",
    "    A[i, j] = True\n",
    "    A[j, k] = True\n",
    "    A[k, i] = True\n",
    "    A = A.tocsr()\n",
    "    A = A + A.T\n",
    "    return A\n",
    "\n",
    "\n",
    "def face_normals(v, f):\n",
    "    \"\"\"\n",
    "    compute normals of faces f\n",
    "    \"\"\"\n",
    "    i, j, k = f.T\n",
    "    # compute edges\n",
    "    e1 = v[j] - v[i]\n",
    "    e2 = v[k] - v[i]\n",
    "    # cross product is face normal\n",
    "    n = np.cross(e1, e2, axis=1)\n",
    "    return normalize(n)\n",
    "\n",
    "\n",
    "def triangle_area(v, f):\n",
    "    i, j, k = f.T\n",
    "    a, b, c = v[i], v[j], v[k]\n",
    "\n",
    "    ac = c - a\n",
    "    bc = c - b\n",
    "\n",
    "    return np.linalg.norm(np.cross(ac, bc, axis=1), axis=1) / 2\n",
    "\n",
    "\n",
    "def vertex_area(v, f):\n",
    "    \"\"\"\n",
    "    compute total area about vertices\n",
    "    3.59ms for 281,724 faces, not bad son\n",
    "    \"\"\"\n",
    "    n = len(v)\n",
    "    A = np.zeros((3, len(f)))\n",
    "\n",
    "    area = triangle_area(v, f)\n",
    "\n",
    "    # set internal angles at vertex location in face array\n",
    "    # using indexes that have duplicate values to increment doesn't work\n",
    "    A[0] = area\n",
    "    A[1] = area\n",
    "    A[2] = area\n",
    "\n",
    "    # some esoteric numpy for summing at duplicated indices\n",
    "    # coo matrices are also an option\n",
    "    data = A.ravel()\n",
    "    cols = f.T.ravel()\n",
    "\n",
    "    M = np.zeros(n)\n",
    "    np.add.at(M, cols, data)\n",
    "\n",
    "    return sp.sparse.diags(M)\n",
    "\n",
    "\n",
    "def barycentric_mass(v, f):\n",
    "    return vertex_area(v, f) / 3\n",
    "\n",
    "\n",
    "# %timeit vertex_area(v4, f4)\n",
    "\n",
    "\n",
    "M = barycentric_mass(v0, f0)\n",
    "assert list(M.diagonal()) == [24, 8, 8, 8, 8, 8, 8]\n",
    "\n",
    "assert len(edges(f0, len(v0))) == 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1834,
   "id": "4a01e115-0d82-4a9b-903d-0dd5a895a310",
   "metadata": {},
   "outputs": [],
   "source": [
    "def edge_triangle_adjacency(f):\n",
    "    \"\"\"\n",
    "    appendix B.3: Edge based gradient\n",
    "    build an |E| x |F| adjacency matrix where each row sums to 0\n",
    "    ~280ms for ~280000 faces, mostly due to sorting\n",
    "    \"\"\"\n",
    "    i, j, k = f.T\n",
    "    # edges\n",
    "    ed = np.hstack([\n",
    "        [i, j],\n",
    "        [j, k],\n",
    "        [k, i],\n",
    "    ])\n",
    "    # ensure a < b\n",
    "    ed.sort(axis=0)\n",
    "    # find indices of unique edges\n",
    "    # rows are indices into unique edges\n",
    "    ed, idx, rows = np.unique(ed, axis=1, return_index=True, return_inverse=True)\n",
    "    # columns are triangle indices\n",
    "    cols = np.tile(np.arange(len(f)), 3)\n",
    "    # use indices to mask duplicate values, s.t. all rows sum to 1 for a closed manifold\n",
    "    data = 0 - np.ones(len(rows), dtype=np.int8)\n",
    "    data[idx] = 1\n",
    "    # return edge-triangle adjacency matrix\n",
    "    return scipy.sparse.coo_matrix((data, (rows, cols)))\n",
    "\n",
    "# assert interior edges sum to 0, exterior edges sum to 1\n",
    "assert np.allclose(edge_triangle_adjacency(f0).sum(axis=1).A.ravel(), [0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6463b97",
   "metadata": {},
   "source": [
    "# Cotangent operator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 871,
   "id": "4ef3188f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cotangent_curvature(v, f):\n",
    "    \"\"\"\n",
    "    we can sum the contribution of all adjacent angles,\n",
    "    then subtract the contribution of all interior angles.\n",
    "    \n",
    "    using edges would probably avoid some redundant work here (as above).\n",
    "\n",
    "    133ms seconds for 281,724 faces. igl is 52.2ms.\n",
    "    \"\"\"\n",
    "    n = len(v)\n",
    "    \n",
    "    # indices\n",
    "    i, j, k = f.T\n",
    "    a, b, c = v[i], v[j], v[k]\n",
    "\n",
    "    # vectors\n",
    "    ab = b - a\n",
    "    ac = c - a\n",
    "    bc = c - b\n",
    "    \n",
    "    # big chungus cotangent computation\n",
    "    abc = np.einsum('ij,ij->i', ab, ac) / np.linalg.norm(np.cross( ab, ac, axis=1), axis=1)\n",
    "    bac = np.einsum('ij,ij->i',-ab, bc) / np.linalg.norm(np.cross(-ab, bc, axis=1), axis=1)\n",
    "    cab = np.einsum('ij,ij->i',-ac,-bc) / np.linalg.norm(np.cross(-ac,-bc, axis=1), axis=1)\n",
    "\n",
    "    # set weights for opposite edges\n",
    "    # a csr_matrix will sum the quantities for us!\n",
    "    data = np.hstack([cab, abc, bac])\n",
    "    rows = np.hstack([i,   j,   k, ])\n",
    "    cols = np.hstack([j,   k,   i, ])\n",
    "    T = sp.sparse.csr_matrix((data, (rows, cols)))\n",
    "\n",
    "    # mad gains by flipping across the diagonal ;)\n",
    "    T = T + T.T\n",
    "\n",
    "    # Nearly there. sum the rows and use as diagonal.\n",
    "    S = sp.sparse.diags(T.sum(axis=1).A.ravel())\n",
    "    T = T - S\n",
    "\n",
    "    # i'm never doing this again\n",
    "    # divide by two as we have computed k_1 + k_2\n",
    "    return T / 2\n",
    "\n",
    "\n",
    "# %timeit cotangent_curvature(v7, f7)\n",
    "\n",
    "C = cotangent_curvature(v0, f0)\n",
    "T = np.diag(np.round((180 / np.pi) * C.todense()))\n",
    "\n",
    "assert list(T) == [-205, -73, -60, -73, -73, -60, -73]\n",
    "assert np.sum(C) < 1e-6"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbe9fc4e-e095-493b-9734-b2e0456668fa",
   "metadata": {},
   "source": [
    "### Check that mean curvature works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 872,
   "id": "75b3e726",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "047de47f85d744da8f326624fd9014d1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Renderer(camera=PerspectiveCamera(children=(DirectionalLight(color='white', intensity=0.6, position=(28.620000â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<meshplot.Viewer.Viewer at 0x15bf8f520>"
      ]
     },
     "execution_count": 872,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def mean_curvature_metric(v, f):\n",
    "    M = barycentric_mass(v, f)\n",
    "    C = cotangent_curvature(v, f)\n",
    "    Mi = sp.sparse.diags(1 / M.diagonal())\n",
    "    Hn = -Mi @ C @ v\n",
    "    H  = np.linalg.norm(Hn, axis=1)\n",
    "    return H\n",
    "\n",
    "\n",
    "c7 = percentile_clip(mean_curvature_metric(v7, f7), 5)\n",
    "\n",
    "mp.plot(v7, f7, c7)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9299580-0a2b-40e6-8883-ea381c7ee3e7",
   "metadata": {},
   "source": [
    "### crazy stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1172,
   "id": "67eba346-806b-4e66-844c-06713d549b88",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rows_in(a, b):\n",
    "    \"\"\"\n",
    "    return mask of a if row is in b\n",
    "    we need to cast each row as a bytestring to perform efficient set operations\n",
    "    absolute shenanigans\n",
    "    \"\"\"\n",
    "    a_rows = np.ascontiguousarray(a)\n",
    "    b_rows = np.ascontiguousarray(b)\n",
    "    a_rows = a_rows.view((a_rows.dtype.descr * a_rows.shape[1]))\n",
    "    b_rows = b_rows.view((b_rows.dtype.descr * b_rows.shape[1]))\n",
    "    return np.isin(a_rows, b_rows).ravel()\n",
    "\n",
    "\n",
    "def rowhash(a):\n",
    "    a_rows = np.ascontiguousarray(a)\n",
    "    return a_rows.view((a_rows.dtype.descr * a_rows.shape[1])).ravel()\n",
    "\n",
    "\n",
    "def edge_gradient(v, f):\n",
    "    # we need a sparse matrix of size |E| x |F|\n",
    "    # this is the \"jump discontinuity\" between shared edges\n",
    "    # in practice this is just +-1 for edges that are members of the triangle,\n",
    "    # with the sign representing direction.\n",
    "    # the paper states that all rows should sum to 1\n",
    "    # this is presumably only true for closed manifolds\n",
    "    \n",
    "    # stack forward and reverse edges\n",
    "    ed = edges(f, len(v))\n",
    "    ei = np.arange(len(ed))\n",
    "    ed = np.vstack([ed, np.fliplr(ed)])\n",
    "    ei = np.hstack([ei, ei])\n",
    "\n",
    "    # build edges from corners\n",
    "    # these are incomplete and contain duplicates\n",
    "    ij = f[:, [0, 1]]\n",
    "    jk = f[:, [1, 2]]\n",
    "    ki = f[:, [2, 0]]\n",
    "    \n",
    "    # in reverse order, present the edges in reverse\n",
    "    ji = f[::-1, [1, 0]]\n",
    "    kj = f[::-1, [2, 1]]\n",
    "    ik = f[::-1, [0, 2]]\n",
    "    \n",
    "    # stack them all, alternating between forward and opposite edges\n",
    "    # ensure indexing scheme matches alternate scheme\n",
    "    fe = np.vstack([ij, ji, jk, kj, ki, ik])\n",
    "    fi = np.arange(0, len(f))\n",
    "    fi = np.hstack([fi, fi[::-1]])\n",
    "    fi = np.tile(fi, 3)\n",
    "\n",
    "    # find indices of fe\n",
    "    a, b, c = np.intersect1d(rowhash(ed), rowhash(fe), return_indices=True)\n",
    "    print(np.vstack([ei[b], fi[c]]).T)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1173,
   "id": "6c33fec1-8443-4927-aad3-ca3b4da393b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 6]\n",
      " [0 5]\n",
      " [0 4]\n",
      " [0 3]\n",
      " [0 2]\n",
      " [0 1]\n",
      " [1 6]\n",
      " [1 2]\n",
      " [2 3]\n",
      " [3 4]\n",
      " [4 5]\n",
      " [5 6]]\n",
      "[[ 5  0]\n",
      " [ 4  1]\n",
      " [ 3  2]\n",
      " [ 2  3]\n",
      " [ 1  4]\n",
      " [ 0  5]\n",
      " [ 5  5]\n",
      " [ 7  0]\n",
      " [ 6  5]\n",
      " [ 4  1]\n",
      " [ 7  0]\n",
      " [ 8  1]\n",
      " [ 3  2]\n",
      " [ 8  1]\n",
      " [ 9  2]\n",
      " [ 2  3]\n",
      " [ 9  2]\n",
      " [10  3]\n",
      " [ 1  4]\n",
      " [10  3]\n",
      " [11  4]\n",
      " [ 0  4]\n",
      " [ 6  5]\n",
      " [11  4]]\n"
     ]
    }
   ],
   "source": [
    "edge_gradient(v0, f0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a849825b-01a4-4afe-ada3-6d969fe3b152",
   "metadata": {},
   "source": [
    "### Compute Normals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a679fa87-feca-411c-8ae6-36d24dbf476a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decompose_normals(v, f, u0, alpha, n, nonuniform, g):\n",
    "    \"\"\"\n",
    "    decomposeNormals: apply the spectral TV decomposition to a normal vector field f, defined on the triangles of the\n",
    "    domain M, applying the algorithm 3 in the paper, where:\n",
    "    - alpha is the maximum time of diffusion\n",
    "    - nComp is the number fo spectral components to be computed\n",
    "    - reductionParam is the scale parameter for alpha\n",
    "    - nonuniform is a binary flag indicating whether alpha is scaled non-uniformily\n",
    "    \"\"\"\n",
    "    # build the edge gradient and divergence operators on surfaces for TV\n",
    "    G = edge_gradient(M);\n",
    "    A = edges_legths(M);\n",
    "    % AA=spdiag(1./calc_tri_areas(M));\n",
    "    D=-K'*spdiag(A);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b8179a2",
   "metadata": {},
   "source": [
    "## TV Divergence & Gradient Operators"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1a5c399",
   "metadata": {},
   "source": [
    "hack this together\n",
    "\n",
    "$$\n",
    "\\mathbf{G} f\\left(\\mathbf{t}_{i j k}\\right)=\\left(\\begin{array}{cc}\n",
    "\\mathbf{v}_{j}^{\\top}-\\mathbf{v}_{i}^{\\top} \\\\\n",
    "\\mathbf{v}_{k}^{\\top}-\\mathbf{v}_{i}^{\\top}\n",
    "\\end{array}\\right)^{\\top}\\left(\\begin{array}{cc}\n",
    "\\left\\|e_{i j}\\right\\|^{2} & \\left\\langle e_{i j}, e_{i k}\\right\\rangle \\\\\n",
    "\\left\\langle e_{i j}, e_{i k}\\right\\rangle & \\left\\|e_{i k}\\right\\|^{2}\n",
    "\\end{array}\\right)\\left(\\begin{array}{l}\n",
    "f\\left(\\mathbf{v}_{j}\\right)-f\\left(\\mathbf{v}_{i}\\right) \\\\\n",
    "f\\left(\\mathbf{v}_{k}\\right)-f\\left(\\mathbf{v}_{i}\\right)\n",
    "\\end{array}\\right)\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "8465d088",
   "metadata": {},
   "outputs": [],
   "source": [
    "def twonormest(A):\n",
    "    \"\"\"\n",
    "    square root of largest singular value of A?!?\n",
    "    https://en.wikipedia.org/wiki/Matrix_norm\n",
    "    \"\"\"\n",
    "    [e] = scipy.sparse.linalg.svds(A, k=1, return_singular_vectors=False)\n",
    "    return np.sqrt(e)\n",
    "\n",
    "\n",
    "def tv_gradient_operator(v, f, axis):\n",
    "    # indices\n",
    "    i, j, k = f.T\n",
    "\n",
    "    # edges?\n",
    "    e_ij = v[j] - v[i]\n",
    "    e_ik = v[k] - v[i]\n",
    "    \n",
    "    # hstack and reshape into F x 2 x 3\n",
    "    # TODO: can we remove this swapaxes?\n",
    "    A = np.hstack([\n",
    "        e_ij,\n",
    "        e_ik,\n",
    "    ]).reshape(len(f), 2, 3).swapaxes(1, 2)\n",
    "    \n",
    "    e_ij2 = np.sum(e_ij ** 2, axis=1)\n",
    "    e_ik2 = np.sum(e_ik ** 2, axis=1)\n",
    "    \n",
    "    e_min = np.min(np.hstack([np.sqrt(e_ij2), np.sqrt(e_ik2)]))\n",
    "\n",
    "    e_ijik = np.einsum('ij,ij->i', e_ij, e_ik)\n",
    "\n",
    "    B = np.hstack([\n",
    "        [e_ij2, e_ijik, e_ijik, e_ik2],             \n",
    "    ]).reshape(2, 2, len(f)).T\n",
    "\n",
    "    # our 'function' is the X coordinate for now\n",
    "    C = np.array([\n",
    "        v[j][:, axis] - v[i][:, axis],\n",
    "        v[k][:, axis] - v[i][:, axis],\n",
    "    ]).reshape(len(f), 2, 1)\n",
    "\n",
    "    D = A @ B @ C\n",
    "    \n",
    "    rows = np.repeat(np.arange(0, len(f)), 3)\n",
    "    cols = f.ravel()\n",
    "    data = D.ravel()\n",
    "\n",
    "    G = sp.sparse.csr_matrix((data, (rows, cols)))\n",
    "    \n",
    "    #Â compute tau, sigma while we're in toon\n",
    "    N = twonormest(G)\n",
    "    t = e_min / N\n",
    "    \n",
    "    return G, t\n",
    "\n",
    "\n",
    "def tv_gradient_operators(v, f, axis=0):\n",
    "    \"\"\"\n",
    "    return G and adjoint D\n",
    "    \"\"\"\n",
    "    G, t = tv_gradient_operator(v, f, axis)\n",
    "    A = barycentric_mass(v, f)\n",
    "    T = sp.sparse.diags(triangle_area(v, f))\n",
    "    Ai = sp.sparse.diags(1 / A.diagonal())\n",
    "    D = -Ai @ G.T @ T\n",
    "    return G, D, t\n",
    "\n",
    "\n",
    "# Test that our unsexy mesh produces the correct value for the first row\n",
    "G, t = tv_gradient_operator(v0, f0)\n",
    "assert np.allclose(G.todense().A[0], [2169, -732, 0, 0, 0, 0, 0])\n",
    "\n",
    "# test that we get a value for tau / sigma\n",
    "assert np.allclose(t, 0.083425544)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "id": "031bd26a-04d7-42ee-83ed-cd87a8d638fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "v, f = v7, f7\n",
    "\n",
    "# todo: standardize v?\n",
    "u0 = face_normals(v, f)\n",
    "\n",
    "sub, phi = decompose_normals(v, f, u0, alpha, 40, nonuniform=False, g=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "id": "39db1efb-a2fe-4a60-a6fa-608dc5ffd671",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prox_f(q):\n",
    "    \"\"\"\n",
    "    Equation (16)\n",
    "    Projects q onto the l2 ball\n",
    "    \"\"\"\n",
    "    qT = q.T\n",
    "    qT_norm = np.linalg.norm(qT, axis=0)\n",
    "    indices = qT_norm > 1\n",
    "    qT[:, indices] = qT[:, indices] / qT_norm[indices]\n",
    "    return qT.T\n",
    "\n",
    "A = np.array([\n",
    "    [0  ,   1,   2],  # normalized\n",
    "    [1/2, 1/2, 1/2],  # unchanged\n",
    "    [1/3, 1/3, 1/3],  # unchanged\n",
    "    [1/4, 1/4, 1/4],  # unchanged\n",
    "])\n",
    "proj = prox_f(A)\n",
    "\n",
    "assert np.allclose(proj[0], [0. , 0.4472136 , 0.89442719])\n",
    "assert np.allclose(proj[1], A[1])\n",
    "assert np.allclose(proj[2], A[2])\n",
    "assert np.allclose(proj[3], A[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "id": "cb24eb75-9b0b-4a9c-8155-5336cd3e81d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prox_g(u, u_0, tau, alpha):\n",
    "    \"\"\"\n",
    "    Equation (17)\n",
    "    ???\n",
    "    \"\"\"\n",
    "    return (u + (tau / alpha) * u_0) / (1 + (tau / alpha))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "id": "c7a37009-df9b-4e88-8e71-b2751042d5f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pdhg(v, f, u, u_0, q, alpha, axis=0):\n",
    "    # algorithm 2\n",
    "    G, D, tau = tv_gradient_operators(v, f, axis)\n",
    "    sigma = tau\n",
    "    theta = 0.5\n",
    "    \n",
    "    while True:\n",
    "        u_next = prox_g(u - tau * D @ q, u_0, tau, alpha)\n",
    "        u_bar  = u_next + theta * (u_next - u)\n",
    "        q_next = prox_f(q + sigma * G @ u_bar)\n",
    "        \n",
    "        print(np.linalg.norm(u_next - u))\n",
    "        if np.linalg.norm(u_next - u) < 1e-6:\n",
    "            break\n",
    "\n",
    "        u = u_next\n",
    "        q = q_next\n",
    "    return u"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "id": "488378cb-a2d6-4ed3-a3c6-9d1a02fb4d70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0948308170645484e-12\n",
      "1.0822538358357315e-12\n",
      "1.040196331096403e-12\n",
      "9.876057739526858e-13\n",
      "9.903753955288679e-13\n",
      "[[ 23.082001  96.296005 -18.754002]\n",
      " [ 23.042002  96.040001 -18.974001]\n",
      " [ 23.162001  96.074005 -18.496   ]\n",
      " ...\n",
      " [ 24.982     78.830002 -16.602001]\n",
      " [ 55.364002  92.348007  -6.774   ]\n",
      " [ 55.476002  92.530006  -6.914001]]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "13b77126b16e4d41b224ab38f025e631",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Renderer(camera=PerspectiveCamera(children=(DirectionalLight(color='white', intensity=0.6, position=(28.620000â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<meshplot.Viewer.Viewer at 0x15aec1610>"
      ]
     },
     "execution_count": 369,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def solve(v, f, axis):\n",
    "    \"\"\"\n",
    "    The algorithm simply evolves the input signal by N discrete steps along the TV flow;\n",
    "    each iteration moves a step forward, with diffusion time equal to Î±.\n",
    "    As changes happen quickly for small t and tend to become slower for larger t\n",
    "    we iteratively increase the step size Î± of the evolution.\n",
    "    \n",
    "    Subsequently, the spectral representation Ï†t is constructed incrementally using finite differences,\n",
    "    such that the integral of Eq. (12) becomes a simple weighted sum over the Ï†t.\n",
    "    We give selection strategies for Î± and N in Appendix B.4.\n",
    "    \"\"\"\n",
    "    n = 5  # number of time steps ~= number of features?!\n",
    "    \n",
    "    u_0 = v[:, axis]  # input signal\n",
    "    u_t = np.zeros((n, *u_0.shape))  #Â feature stack\n",
    "    p_t = np.zeros_like(u_t)  # spectral representation\n",
    "\n",
    "    alpha = 1e-9  # step size - not sure what this should be\n",
    "    \n",
    "    # initialize u\n",
    "    u = u_0\n",
    "    \n",
    "    # initialize q\n",
    "    q = np.zeros_like(f[:, axis])\n",
    "\n",
    "    for t in range(0, n):\n",
    "        u_t[t] = pdhg(v, f, u, u_0, q, alpha, axis=0)\n",
    "        p_t[t] = u_t[t] - u_t[t-1]  # 0 on first run?\n",
    "        alpha  = alpha + alpha * 0.1\n",
    "        u_0    = u_t[t]\n",
    "    return p_t\n",
    "\n",
    "\n",
    "p_t = solve(v7, f7, axis=0)\n",
    "\n",
    "v7_t = np.vstack([p_t[0], v7[:, 1], v7[:, 2]]).T\n",
    "\n",
    "print(v7_t)\n",
    "\n",
    "mp.plot(v7_t, f7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dbff9a4-8bff-4840-94d6-ec02ca1a413c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
