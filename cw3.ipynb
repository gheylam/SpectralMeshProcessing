{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "accepted-bubble",
   "metadata": {},
   "source": [
    "# SPoOkY Meshes ðŸ‘»"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "sapphire-medium",
   "metadata": {},
   "outputs": [],
   "source": [
    "import base64\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import scipy.sparse\n",
    "import scipy.sparse.linalg\n",
    "import pymeshlab\n",
    "import k3d\n",
    "import IPython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "neural-enlargement",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_mesh(filename):\n",
    "    ms = pymeshlab.MeshSet()\n",
    "    ms.load_new_mesh(filename)\n",
    "    v = ms.current_mesh().vertex_matrix()\n",
    "    f = ms.current_mesh().face_matrix()\n",
    "    return v, f\n",
    "\n",
    "\n",
    "def save_mesh(filename, v, f):\n",
    "    ms = pymeshlab.MeshSet()\n",
    "    m  = pymeshlab.Mesh(vertex_matrix=vx, face_matrix=f)\n",
    "    ms.add_mesh(m)\n",
    "    ms.save_current_mesh(filename)\n",
    "\n",
    "\n",
    "v1, f1 = load_mesh('cw2_meshes/curvatures/plane.obj')\n",
    "v2, f2 = load_mesh('cw2_meshes/curvatures/lilium_s.obj')\n",
    "v3, f3 = load_mesh('cw2_meshes/decompose/armadillo.obj')\n",
    "v4, f4 = load_mesh('cw2_meshes/smoothing/fandisk_ns.obj')\n",
    "v5, f5 = load_mesh('cw2_meshes/smoothing/plane_ns.obj')\n",
    "v7, f7 = load_mesh('sappho-hires.obj')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "mature-jackson",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(v):\n",
    "    \"\"\"\n",
    "    recenter points\n",
    "    \"\"\"\n",
    "    if not np.any(v):\n",
    "        return v\n",
    "    return 2 * (v - v.min()) / (v.max() - v.min()) - 1\n",
    "\n",
    "\n",
    "def percentile_clip(h, n):\n",
    "    \"\"\"\n",
    "    reject outlier points\n",
    "    \"\"\"\n",
    "    return np.clip(h, np.percentile(h, n), np.percentile(h, 100 - n))\n",
    "\n",
    "\n",
    "def plot(grid=False):\n",
    "    \"\"\"\n",
    "    create a plot for visualization\n",
    "    \"\"\"\n",
    "    plot = k3d.plot(grid_visible=grid)\n",
    "    return plot\n",
    "\n",
    "\n",
    "def plot_mesh(p, v, f, h, t=None, r=None, wf=False):\n",
    "    m = k3d.mesh(v.astype(np.float32), f.astype(np.uint32), attribute=h, wireframe=wf)\n",
    "    m.transform.translation = t\n",
    "    m.transform.rotation = r\n",
    "    p += m\n",
    "    return m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "emerging-queensland",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unsexy test mesh for debugging\n",
    "v0 = np.array([\n",
    "    [ 0, 0, 0],\n",
    "    [-3, 4, 0],\n",
    "    [-6, 0, 0],\n",
    "    [-3,-4, 0],\n",
    "    [ 3,-4, 0],\n",
    "    [ 6, 0, 0],\n",
    "    [ 3, 4, 0],\n",
    "], dtype=np.float32)\n",
    "\n",
    "f0 = np.array([\n",
    "    [0, 1, 2],\n",
    "    [0, 2, 3],\n",
    "    [0, 3, 4],\n",
    "    [0, 4, 5],\n",
    "    [0, 5, 6],\n",
    "    [0, 1, 6],\n",
    "], dtype=np.int32)\n",
    "\n",
    "# perturbed vertex indices to throw off naive algorithms\n",
    "# f0 = np.array([\n",
    "#     [1, 0, 2],\n",
    "#     [2, 3, 0],\n",
    "#     [0, 3, 4],\n",
    "#     [4, 0, 5],\n",
    "#     [5, 6, 0],\n",
    "#     [6, 1, 0],\n",
    "# ], dtype=np.int32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fallen-fifty",
   "metadata": {},
   "source": [
    "## Laplace-Beltrami and Friends"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "legislative-domain",
   "metadata": {},
   "source": [
    "### Vertex Area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "efficient-purchase",
   "metadata": {},
   "outputs": [],
   "source": [
    "def triangle_area(v, f):\n",
    "    i, j, k = f.T\n",
    "    a, b, c = v[i], v[j], v[k]\n",
    "\n",
    "    ac = c - a\n",
    "    bc = c - b\n",
    "\n",
    "    return np.linalg.norm(np.cross(ac, bc, axis=1), axis=1) / 2\n",
    "\n",
    "\n",
    "def vertex_area(v, f):\n",
    "    \"\"\"\n",
    "    compute total area about vertices\n",
    "    3.59ms for 281,724 faces, not bad son\n",
    "    \"\"\"\n",
    "    n = len(v)\n",
    "    A = np.zeros((3, len(f)))\n",
    "\n",
    "    area = triangle_area(v, f)\n",
    "\n",
    "    # set internal angles at vertex location in face array\n",
    "    # using indexes that have duplicate values to increment doesn't work\n",
    "    A[0] = area\n",
    "    A[1] = area\n",
    "    A[2] = area\n",
    "\n",
    "    # some esoteric numpy for summing at duplicated indices\n",
    "    # coo matrices are also an option\n",
    "    data = A.ravel()\n",
    "    cols = f.T.ravel()\n",
    "\n",
    "    M = np.zeros(n)\n",
    "    np.add.at(M, cols, data)\n",
    "\n",
    "    return sp.sparse.diags(M)\n",
    "\n",
    "\n",
    "def barycentric_mass(v, f):\n",
    "    return vertex_area(v, f) / 3\n",
    "\n",
    "\n",
    "# %timeit vertex_area(v4, f4)\n",
    "\n",
    "\n",
    "M = barycentric_mass(v0, f0)\n",
    "assert list(M.diagonal()) == [24, 8, 8, 8, 8, 8, 8]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "electrical-organization",
   "metadata": {},
   "source": [
    "### Cotangent operator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "labeled-being",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cotangent_curvature(v, f):\n",
    "    \"\"\"\n",
    "    we can sum the contribution of all adjacent angles,\n",
    "    then subtract the contribution of all interior angles.\n",
    "    \n",
    "    using edges would probably avoid some redundant work here (as above).\n",
    "\n",
    "    133ms seconds for 281,724 faces. igl is 52.2ms.\n",
    "    \"\"\"\n",
    "    n = len(v)\n",
    "    \n",
    "    # indices\n",
    "    i, j, k = f.T\n",
    "    a, b, c = v[i], v[j], v[k]\n",
    "\n",
    "    # vectors\n",
    "    ab = b - a\n",
    "    ac = c - a\n",
    "    bc = c - b\n",
    "    \n",
    "    # big chungus cotangent computation\n",
    "    abc = np.einsum('ij,ij->i', ab, ac) / np.linalg.norm(np.cross( ab, ac, axis=1), axis=1)\n",
    "    bac = np.einsum('ij,ij->i',-ab, bc) / np.linalg.norm(np.cross(-ab, bc, axis=1), axis=1)\n",
    "    cab = np.einsum('ij,ij->i',-ac,-bc) / np.linalg.norm(np.cross(-ac,-bc, axis=1), axis=1)\n",
    "\n",
    "    # set weights for opposite edges\n",
    "    # a csr_matrix will sum the quantities for us!\n",
    "    data = np.hstack([cab, abc, bac])\n",
    "    rows = np.hstack([i,   j,   k, ])\n",
    "    cols = np.hstack([j,   k,   i, ])\n",
    "    T = sp.sparse.csr_matrix((data, (rows, cols)))\n",
    "\n",
    "    # mad gains by flipping across the diagonal ;)\n",
    "    T = T + T.T\n",
    "\n",
    "    # Nearly there. sum the rows and use as diagonal.\n",
    "    S = sp.sparse.diags(T.sum(axis=1).A.ravel())\n",
    "    T = T - S\n",
    "\n",
    "    # i'm never doing this again\n",
    "    # divide by two as we have computed k_1 + k_2\n",
    "    return T / 2\n",
    "\n",
    "\n",
    "# %timeit cotangent_curvature(v7, f7)\n",
    "\n",
    "C = cotangent_curvature(v0, f0)\n",
    "T = np.diag(np.round((180 / np.pi) * C.todense()))\n",
    "\n",
    "assert list(T) == [-205, -73, -60, -73, -73, -60, -73]\n",
    "assert np.sum(C) < 1e-6"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "focused-tumor",
   "metadata": {},
   "source": [
    "## TV Divergence & Gradient Operators"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fatal-broadcast",
   "metadata": {},
   "source": [
    "hack this together\n",
    "\n",
    "$$\n",
    "\\mathbf{G} f\\left(\\mathbf{t}_{i j k}\\right)=\\left(\\begin{array}{cc}\n",
    "\\mathbf{v}_{j}^{\\top}-\\mathbf{v}_{i}^{\\top} \\\\\n",
    "\\mathbf{v}_{k}^{\\top}-\\mathbf{v}_{i}^{\\top}\n",
    "\\end{array}\\right)^{\\top}\\left(\\begin{array}{cc}\n",
    "\\left\\|e_{i j}\\right\\|^{2} & \\left\\langle e_{i j}, e_{i k}\\right\\rangle \\\\\n",
    "\\left\\langle e_{i j}, e_{i k}\\right\\rangle & \\left\\|e_{i k}\\right\\|^{2}\n",
    "\\end{array}\\right)\\left(\\begin{array}{l}\n",
    "f\\left(\\mathbf{v}_{j}\\right)-f\\left(\\mathbf{v}_{i}\\right) \\\\\n",
    "f\\left(\\mathbf{v}_{k}\\right)-f\\left(\\mathbf{v}_{i}\\right)\n",
    "\\end{array}\\right)\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "valued-place",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tv_gradient_operator(v, f, axis=0):\n",
    "    # indices\n",
    "    i, j, k = f.T\n",
    "\n",
    "    # edges?\n",
    "    e_ij = v[j] - v[i]\n",
    "    e_ik = v[k] - v[i]\n",
    "\n",
    "    # hstack and reshape into F x 2 x 3\n",
    "    # TODO: can we remove this swapaxes?\n",
    "    A = np.hstack([\n",
    "        e_ij,\n",
    "        e_ik,\n",
    "    ]).reshape(len(f), 2, 3).swapaxes(1, 2)\n",
    "\n",
    "    e_ij2 = np.sum(e_ij ** 2, axis=1)\n",
    "    e_ik2 = np.sum(e_ik ** 2, axis=1)\n",
    "\n",
    "    e_ijik = np.einsum('ij,ij->i', e_ij, e_ik)\n",
    "\n",
    "    B = np.hstack([\n",
    "        [e_ij2, e_ijik, e_ijik, e_ik2],             \n",
    "    ]).reshape(2, 2, len(f)).T\n",
    "\n",
    "    # our 'function' is the X coordinate for now\n",
    "    C = np.array([\n",
    "        v[j][:, axis] - v[i][:, axis],\n",
    "        v[k][:, axis] - v[i][:, axis],\n",
    "    ]).reshape(len(f), 2, 1)\n",
    "\n",
    "    D = A @ B @ C\n",
    "    \n",
    "    rows = np.repeat(np.arange(0, len(f)), 3)\n",
    "    cols = f.ravel()\n",
    "    data = D.ravel()\n",
    "\n",
    "    G = sp.sparse.csr_matrix((data, (rows, cols)))\n",
    "    return G\n",
    "\n",
    "# Test that our unsexy mesh produces the correct value for the first row\n",
    "assert np.allclose(tv_gradient_operator(v0, f0).todense().A[0], [2169, -732, 0, 0, 0, 0, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "derived-danish",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "91343e27149145628570293eaa43b1a5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def mean_curvature_metric(v, f):\n",
    "    M = barycentric_mass(v, f)\n",
    "    C = cotangent_curvature(v, f)\n",
    "    Mi = sp.sparse.diags(1 / M.diagonal())\n",
    "    Hn = -Mi @ C @ v\n",
    "    H  = np.linalg.norm(Hn, axis=1)\n",
    "    return H\n",
    "\n",
    "def tv_gradient_metric(v, f, a):\n",
    "    G = tv_gradient_operator(v, f, a)\n",
    "    A = barycentric_mass(v, f)\n",
    "\n",
    "    T = sp.sparse.diags(triangle_area(v, f))\n",
    "\n",
    "    Ai = sp.sparse.diags(1/A.diagonal())\n",
    "\n",
    "    D = -Ai @ G.T @ T\n",
    "    \n",
    "    H = scipy.sparse.linalg.norm(D, axis=1)\n",
    "    return H\n",
    "\n",
    "h1 = normalize(percentile_clip(tv_gradient_metric(v7, f7, 0), 5))\n",
    "h2 = normalize(percentile_clip(tv_gradient_metric(v7, f7, 1), 5))\n",
    "h3 = normalize(percentile_clip(tv_gradient_metric(v7, f7, 2), 5))\n",
    "\n",
    "p = plot()\n",
    "plot_mesh(p, v7, f7, h1, t=[-105, 0, 0])\n",
    "plot_mesh(p, v7, f7, h2, t=[-45, 0, 0])\n",
    "plot_mesh(p, v7, f7, h3, t=[15, 0, 0])\n",
    "\n",
    "p.display()\n",
    "p.camera = [0, 55, 700, 0, 55, 0, 0, 1, 0]\n",
    "p.camera_fov = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "earlier-culture",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
